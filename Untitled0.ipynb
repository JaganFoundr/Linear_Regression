{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPswq649Ic35Wmq2jnXuEMP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaganFoundr/PyTorchNN/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing library\n",
        "import torch"
      ],
      "metadata": {
        "id": "NHpAQR4D6VAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a tensor\n",
        "tensor=torch.tensor(7.)\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ey0B1trABcNh",
        "outputId": "0a3bdddb-d450-4601-ebca-bdf54ca35979"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7.)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the datatype\n",
        "tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJ3BlgdeCE85",
        "outputId": "4e994e5f-b0a6-498e-940d-702fe817eeb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vector\n",
        "tensor=torch.tensor([1.,2,3,4,5])\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_B9sefWCRY1",
        "outputId": "202cdd88-48fb-4ed4-a3fd-534e91d94f3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3., 4., 5.])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#matrix\n",
        "tensor=torch.tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9gebeUvCjoV",
        "outputId": "69ec2306-1ca7-4353-fd78-c79db9776db9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6],\n",
              "        [7, 8, 9]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#more complex ndimensional array\n",
        "tensor=torch.tensor([[[3,9],[4,0]],[[5,5],[6,4]],[[8,2],[9,5]]])\n",
        "tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPGX901HC1QR",
        "outputId": "cfba097e-f3e7-4f44-a498-2c9be3e6c519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating tensor with an additional parameter requires_grad\n",
        "x=torch.tensor([3.,5,2,4])\n",
        "w=torch.tensor([4.,5,6,7],requires_grad=True)\n",
        "b=torch.tensor(5.,requires_grad=True)"
      ],
      "metadata": {
        "id": "vW6uBF59DWaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output=w*x+b\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRnksQsgHkV3",
        "outputId": "abefba37-f416-4933-dedf-7b74e9e8d58b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([17., 30., 17., 33.], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.grad)\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcRm_CYLWtU0",
        "outputId": "03b96b07-c751-4c0f-f864-dc489faba92e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "None\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output.backward()\n",
        "print(x.grad)\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "aBiCw7vuXeew",
        "outputId": "0edf598e-af9e-4e94-cfc5-c843900227a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "grad can be implicitly created only for scalar outputs",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-62cb14b96abd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_grads_batched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m    196\u001b[0m                     \u001b[0mout_numel_is_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mout_numel_is_1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m                     raise RuntimeError(\n\u001b[0m\u001b[1;32m    199\u001b[0m                         \u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                     )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#integration with numpy\n",
        "import numpy as np\n",
        "array=np.array([[1,2],[2,3]])\n",
        "array\n",
        "array.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVK4PlKHX5Qi",
        "outputId": "4a380f82-af7f-4960-f66a-cebe6e8842ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('int64')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor=torch.from_numpy(array)\n",
        "tensor\n",
        "tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hufC2TW0ZyaX",
        "outputId": "10939853-c453-4be5-8e67-16538f06eef4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "back_to_numpy=tensor.numpy()\n",
        "back_to_numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_vLn8HgZ8-a",
        "outputId": "1f15694b-c74d-4145-e64d-5a95d4aebe71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2],\n",
              "       [2, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# linear regression - import all the necessary libraries\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "#inputs (temperature, rainfall, humidity)\n",
        "inputs=np.array([[73,67,45],\n",
        "                 [91,88,64],\n",
        "                 [87,134,58],\n",
        "                 [102,43,37],\n",
        "                 [69,96,70]],dtype='float32')\n",
        "\n",
        "print('inputs: ',inputs)\n",
        "\n",
        "print(\"---------------------------------------------\")\n",
        "\n",
        "#targets (apples, oranges)\n",
        "targets=np.array([[56,70],\n",
        "                 [81,101],\n",
        "                 [119,133],\n",
        "                 [22,37],\n",
        "                 [103,119]],dtype='float32')\n",
        "print('targets: ',targets)\n",
        "\n",
        "print(\"---------------------------------------------\")\n",
        "\n",
        "#convert from numpy format to tensor format\n",
        "inputs=torch.from_numpy(inputs)\n",
        "print('tensor inputs: ',inputs)\n",
        "\n",
        "print(\"---------------------------------------------\")\n",
        "\n",
        "targets=torch.from_numpy(targets)\n",
        "print('tensor targets: ',targets)\n",
        "\n",
        "print(\"---------------------------------------------\")\n",
        "\n",
        "#defining weights and biases\n",
        "w = torch.randn(2,3,requires_grad=True)\n",
        "print('random weights: ',w)\n",
        "\n",
        "print(\"---------------------------------------------\")\n",
        "\n",
        "b = torch.randn(2, requires_grad=True)\n",
        "print('random bias: ',b)\n",
        "\n",
        "print(\"---------------------------------------------\")\n",
        "\n",
        "#defining the model\n",
        "def model(x):\n",
        "  return (x @ w.t() + b)\n",
        "\n",
        "print(\"---------------------------------------------\")\n",
        "\n",
        "#defining a loss function\n",
        "def mse(pred,tar):\n",
        "  difference=pred-tar\n",
        "  return torch.sum(difference*difference)/difference.numel()\n",
        "\n",
        "predictions = model(inputs)\n",
        "print(\"prediction: \",predictions)\n",
        "\n",
        "print(\"---------------------------------------------\")\n",
        "\n",
        "#training loop\n",
        "for i in range(1000):\n",
        "\n",
        "  #making predctions\n",
        "  predictions = model(inputs)\n",
        "\n",
        "  # calculating the loss\n",
        "  loss=mse(predictions,targets)\n",
        "\n",
        "  print(\"loss: \",loss)\n",
        "\n",
        "  #computing the gradients\n",
        "  loss.backward()\n",
        "\n",
        "  #updating the weights without tracking the gradients\n",
        "  with torch.no_grad():\n",
        "    lr=0.00001\n",
        "    w-=w.grad * lr\n",
        "    b-=b.grad * lr\n",
        "    #emptying the gradient\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "\n",
        "print(\"---------------------------------------------\")\n",
        "\n",
        "\n",
        "#checking the new loss\n",
        "print('loss: ',loss)\n",
        "\n",
        "print(\"---------------------------------------------\")\n",
        "\n",
        "print(\"new_prediction: \",predictions)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CdEho-pTaSMz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7193be89-ebb4-4a17-9aee-045acb145099"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs:  [[ 73.  67.  45.]\n",
            " [ 91.  88.  64.]\n",
            " [ 87. 134.  58.]\n",
            " [102.  43.  37.]\n",
            " [ 69.  96.  70.]]\n",
            "---------------------------------------------\n",
            "targets:  [[ 56.  70.]\n",
            " [ 81. 101.]\n",
            " [119. 133.]\n",
            " [ 22.  37.]\n",
            " [103. 119.]]\n",
            "---------------------------------------------\n",
            "tensor inputs:  tensor([[ 73.,  67.,  45.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.]])\n",
            "---------------------------------------------\n",
            "tensor targets:  tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n",
            "---------------------------------------------\n",
            "random weights:  tensor([[-1.9292, -1.5104,  0.1037],\n",
            "        [ 0.9794, -1.1571, -0.6768]], requires_grad=True)\n",
            "---------------------------------------------\n",
            "random bias:  tensor([-1.6547, -0.6466], requires_grad=True)\n",
            "---------------------------------------------\n",
            "---------------------------------------------\n",
            "prediction:  tensor([[-239.0154,  -37.1268],\n",
            "        [-303.4889,  -56.6540],\n",
            "        [-365.8708, -109.7357],\n",
            "        [-259.5425,   24.4592],\n",
            "        [-272.5077,  -91.5178]], grad_fn=<AddBackward0>)\n",
            "---------------------------------------------\n",
            "loss:  tensor(82996.4219, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(56475.6172, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(38611.9297, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(26577.1504, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(18467.0645, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12999.5693, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(9311.4150, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(6821.3735, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(5138.1094, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(3998.1304, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(3224.0305, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(2696.3579, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(2334.6868, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(2084.8635, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1910.4277, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1786.8274, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1697.5325, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1631.4114, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1580.9680, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1541.1549, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1508.5730, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1480.9323, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1456.6895, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1434.8059, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1414.5797, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1395.5388, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1377.3636, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1359.8385, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1342.8179, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1326.2015, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1309.9229, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1293.9348, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1278.2058, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1262.7129, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1247.4410, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1232.3783, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1217.5162, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1202.8484, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1188.3699, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1174.0764, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1159.9650, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1146.0314, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1132.2733, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1118.6891, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1105.2751, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1092.0291, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1078.9495, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1066.0336, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1053.2797, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1040.6857, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1028.2490, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1015.9683, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(1003.8410, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(991.8658, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(980.0402, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(968.3628, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(956.8314, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(945.4442, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(934.1995, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(923.0954, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(912.1304, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(901.3019, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(890.6094, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(880.0505, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(869.6232, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(859.3265, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(849.1587, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(839.1176, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(829.2025, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(819.4108, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(809.7416, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(800.1931, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(790.7639, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(781.4526, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(772.2574, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(763.1771, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(754.2100, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(745.3551, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(736.6106, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(727.9752, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(719.4477, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(711.0265, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(702.7103, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(694.4979, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(686.3881, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(678.3793, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(670.4703, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(662.6603, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(654.9473, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(647.3306, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(639.8086, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(632.3806, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(625.0448, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(617.8007, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(610.6469, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(603.5822, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(596.6052, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(589.7152, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(582.9109, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(576.1915, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(569.5557, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(563.0024, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(556.5306, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(550.1393, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(543.8276, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(537.5945, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(531.4388, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(525.3594, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(519.3558, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(513.4269, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(507.5716, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(501.7890, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(496.0783, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(490.4383, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(484.8687, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(479.3680, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(473.9356, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(468.5708, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(463.2725, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(458.0397, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(452.8722, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(447.7685, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(442.7283, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(437.7505, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(432.8343, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(427.9792, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(423.1842, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(418.4486, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(413.7717, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(409.1527, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(404.5909, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(400.0854, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(395.6360, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(391.2413, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(386.9012, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(382.6147, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(378.3812, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(374.2000, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(370.0707, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(365.9922, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(361.9642, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(357.9859, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(354.0567, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(350.1761, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(346.3434, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(342.5579, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(338.8191, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(335.1265, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(331.4795, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(327.8773, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(324.3196, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(320.8057, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(317.3351, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(313.9073, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(310.5216, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(307.1777, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(303.8748, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(300.6127, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(297.3907, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(294.2083, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(291.0649, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(287.9603, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(284.8938, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(281.8649, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(278.8732, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(275.9182, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(272.9995, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(270.1167, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(267.2693, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(264.4566, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(261.6786, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(258.9345, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(256.2240, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(253.5468, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(250.9022, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(248.2901, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(245.7099, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(243.1613, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(240.6438, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(238.1571, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(235.7008, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(233.2746, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(230.8778, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(228.5105, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(226.1719, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(223.8618, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(221.5799, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(219.3259, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(217.0994, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(214.8999, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(212.7272, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(210.5809, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(208.4608, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(206.3664, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(204.2975, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(202.2536, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(200.2347, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(198.2403, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(196.2701, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(194.3237, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(192.4010, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(190.5016, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(188.6252, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(186.7714, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(184.9402, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(183.1311, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(181.3439, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(179.5782, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(177.8340, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(176.1107, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(174.4084, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(172.7265, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(171.0649, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(169.4233, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(167.8015, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(166.1993, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(164.6163, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(163.0524, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(161.5073, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(159.9807, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(158.4725, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(156.9824, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(155.5101, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(154.0557, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(152.6185, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(151.1985, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(149.7957, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(148.4096, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(147.0400, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(145.6869, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(144.3499, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(143.0289, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(141.7236, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(140.4340, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(139.1596, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(137.9005, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(136.6564, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(135.4270, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(134.2123, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(133.0120, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(131.8259, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(130.6540, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(129.4959, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(128.3515, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(127.2208, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(126.1034, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(124.9993, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(123.9081, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(122.8299, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(121.7644, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(120.7115, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(119.6710, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(118.6427, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(117.6266, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(116.6225, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(115.6301, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(114.6493, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(113.6801, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(112.7223, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(111.7756, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(110.8401, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(109.9155, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(109.0017, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(108.0987, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(107.2061, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(106.3240, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(105.4521, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(104.5904, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(103.7387, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(102.8970, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(102.0650, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(101.2427, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(100.4299, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(99.6265, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(98.8324, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(98.0476, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(97.2717, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(96.5049, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(95.7469, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(94.9976, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(94.2570, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(93.5249, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(92.8011, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(92.0858, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(91.3785, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(90.6794, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(89.9884, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(89.3052, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(88.6298, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(87.9622, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(87.3021, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(86.6496, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(86.0045, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(85.3667, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(84.7362, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(84.1128, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(83.4965, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(82.8872, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(82.2847, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(81.6891, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(81.1002, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(80.5179, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(79.9422, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(79.3729, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(78.8100, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(78.2535, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(77.7032, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(77.1591, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(76.6210, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(76.0889, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(75.5628, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(75.0425, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(74.5280, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(74.0192, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(73.5161, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(73.0186, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(72.5265, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(72.0399, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(71.5587, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(71.0827, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(70.6120, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(70.1465, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(69.6861, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(69.2307, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(68.7803, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(68.3349, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(67.8943, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(67.4585, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(67.0274, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(66.6011, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(66.1793, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(65.7622, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(65.3495, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(64.9413, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(64.5375, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(64.1381, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(63.7429, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(63.3520, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(62.9653, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(62.5828, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(62.2043, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(61.8299, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(61.4594, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(61.0929, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(60.7302, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(60.3715, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(60.0165, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(59.6652, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(59.3177, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(58.9739, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(58.6336, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(58.2969, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(57.9637, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(57.6341, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(57.3078, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(56.9850, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(56.6655, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(56.3494, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(56.0365, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(55.7268, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(55.4204, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(55.1171, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(54.8169, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(54.5198, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(54.2257, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(53.9347, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(53.6466, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(53.3614, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(53.0791, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(52.7998, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(52.5232, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(52.2494, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(51.9784, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(51.7101, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(51.4445, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(51.1816, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(50.9213, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(50.6636, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(50.4084, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(50.1558, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(49.9057, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(49.6580, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(49.4128, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(49.1700, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(48.9296, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(48.6915, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(48.4558, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(48.2224, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(47.9912, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(47.7623, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(47.5356, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(47.3111, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(47.0887, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(46.8685, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(46.6504, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(46.4344, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(46.2204, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(46.0085, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(45.7986, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(45.5907, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(45.3847, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(45.1806, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(44.9786, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(44.7783, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(44.5800, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(44.3835, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(44.1888, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(43.9960, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(43.8049, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(43.6156, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(43.4280, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(43.2422, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(43.0580, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(42.8755, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(42.6947, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(42.5155, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(42.3379, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(42.1620, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(41.9876, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(41.8148, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(41.6435, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(41.4738, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(41.3056, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(41.1388, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(40.9735, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(40.8097, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(40.6474, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(40.4864, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(40.3268, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(40.1686, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(40.0119, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(39.8564, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(39.7023, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(39.5496, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(39.3981, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(39.2479, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(39.0990, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(38.9514, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(38.8050, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(38.6598, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(38.5158, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(38.3731, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(38.2316, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(38.0912, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(37.9520, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(37.8140, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(37.6771, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(37.5413, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(37.4066, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(37.2730, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(37.1405, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(37.0091, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(36.8787, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(36.7493, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(36.6210, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(36.4938, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(36.3675, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(36.2423, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(36.1180, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(35.9947, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(35.8724, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(35.7510, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(35.6306, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(35.5111, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(35.3925, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(35.2748, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(35.1581, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(35.0422, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(34.9272, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(34.8131, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(34.6998, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(34.5874, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(34.4758, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(34.3651, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(34.2551, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(34.1461, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(34.0378, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(33.9302, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(33.8235, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(33.7176, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(33.6124, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(33.5080, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(33.4043, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(33.3014, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(33.1992, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(33.0978, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(32.9970, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(32.8969, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(32.7976, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(32.6990, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(32.6010, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(32.5038, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(32.4072, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(32.3112, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(32.2159, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(32.1213, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(32.0273, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(31.9340, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(31.8412, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(31.7491, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(31.6576, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(31.5667, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(31.4764, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(31.3868, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(31.2977, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(31.2091, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(31.1212, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(31.0338, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(30.9470, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(30.8607, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(30.7751, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(30.6899, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(30.6053, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(30.5212, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(30.4376, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(30.3546, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(30.2720, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(30.1900, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(30.1085, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(30.0275, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(29.9470, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(29.8670, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(29.7874, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(29.7083, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(29.6298, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(29.5517, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(29.4740, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(29.3968, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(29.3201, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(29.2437, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(29.1679, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(29.0925, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(29.0175, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(28.9430, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(28.8689, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(28.7952, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(28.7219, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(28.6490, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(28.5765, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(28.5045, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(28.4328, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(28.3616, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(28.2907, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(28.2202, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(28.1502, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(28.0804, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(28.0111, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(27.9422, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(27.8736, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(27.8053, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(27.7375, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(27.6700, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(27.6028, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(27.5360, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(27.4696, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(27.4035, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(27.3377, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(27.2723, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(27.2072, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(27.1424, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(27.0780, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(27.0139, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(26.9501, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(26.8866, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(26.8235, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(26.7606, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(26.6981, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(26.6358, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(26.5739, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(26.5123, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(26.4509, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(26.3899, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(26.3291, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(26.2687, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(26.2085, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(26.1486, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(26.0890, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(26.0297, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(25.9706, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(25.9118, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(25.8533, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(25.7951, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(25.7371, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(25.6793, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(25.6219, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(25.5647, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(25.5078, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(25.4510, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(25.3946, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(25.3384, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(25.2825, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(25.2267, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(25.1713, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(25.1160, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(25.0610, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(25.0063, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(24.9518, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(24.8975, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(24.8434, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(24.7896, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(24.7360, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(24.6826, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(24.6294, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(24.5765, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(24.5237, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(24.4712, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(24.4189, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(24.3668, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(24.3149, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(24.2632, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(24.2118, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(24.1605, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(24.1095, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(24.0586, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(24.0079, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(23.9574, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(23.9072, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(23.8571, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(23.8072, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(23.7575, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(23.7080, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(23.6587, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(23.6096, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(23.5606, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(23.5118, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(23.4633, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(23.4149, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(23.3667, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(23.3186, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(23.2707, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(23.2231, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(23.1755, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(23.1282, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(23.0810, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(23.0339, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(22.9871, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(22.9404, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(22.8939, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(22.8475, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(22.8014, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(22.7553, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(22.7095, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(22.6638, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(22.6182, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(22.5728, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(22.5276, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(22.4825, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(22.4375, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(22.3928, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(22.3481, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(22.3036, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(22.2593, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(22.2151, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(22.1710, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(22.1271, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(22.0834, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(22.0398, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(21.9963, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(21.9530, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(21.9098, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(21.8668, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(21.8238, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(21.7810, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(21.7384, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(21.6959, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(21.6535, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(21.6113, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(21.5692, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(21.5272, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(21.4853, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(21.4436, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(21.4020, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(21.3605, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(21.3192, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(21.2780, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(21.2369, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(21.1959, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(21.1551, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(21.1144, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(21.0738, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(21.0333, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(20.9930, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(20.9527, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(20.9126, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(20.8726, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(20.8327, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(20.7929, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(20.7533, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(20.7137, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(20.6743, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(20.6350, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(20.5958, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(20.5567, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(20.5177, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(20.4789, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(20.4401, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(20.4015, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(20.3629, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(20.3245, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(20.2862, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(20.2480, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(20.2099, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(20.1719, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(20.1339, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(20.0961, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(20.0585, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(20.0208, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(19.9834, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(19.9460, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(19.9087, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(19.8715, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(19.8344, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(19.7974, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(19.7606, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(19.7237, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(19.6870, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(19.6505, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(19.6140, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(19.5776, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(19.5412, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(19.5050, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(19.4689, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(19.4329, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(19.3970, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(19.3611, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(19.3254, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(19.2897, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(19.2541, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(19.2187, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(19.1833, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(19.1480, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(19.1128, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(19.0777, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(19.0426, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(19.0077, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(18.9728, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(18.9381, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(18.9034, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(18.8688, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(18.8343, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(18.7999, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(18.7655, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(18.7313, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(18.6971, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(18.6630, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(18.6290, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(18.5951, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(18.5613, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(18.5275, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(18.4938, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(18.4603, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(18.4267, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(18.3933, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(18.3600, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(18.3267, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(18.2935, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(18.2604, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(18.2274, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(18.1944, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(18.1615, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(18.1287, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(18.0960, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(18.0634, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(18.0308, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(17.9983, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(17.9659, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(17.9336, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(17.9013, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(17.8691, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(17.8370, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(17.8050, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(17.7730, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(17.7411, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(17.7093, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(17.6775, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(17.6459, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(17.6143, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(17.5827, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(17.5512, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(17.5199, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(17.4885, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(17.4573, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(17.4262, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(17.3951, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(17.3640, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(17.3330, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(17.3022, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(17.2713, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(17.2406, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(17.2099, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(17.1793, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(17.1487, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(17.1182, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(17.0878, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(17.0575, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(17.0272, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(16.9970, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(16.9668, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(16.9368, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(16.9068, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(16.8768, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(16.8469, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(16.8171, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(16.7873, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(16.7577, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(16.7280, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(16.6985, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(16.6689, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(16.6395, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(16.6102, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(16.5808, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(16.5516, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(16.5224, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(16.4933, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(16.4643, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(16.4353, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(16.4063, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(16.3775, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(16.3487, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(16.3199, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(16.2913, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(16.2626, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(16.2341, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(16.2056, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(16.1771, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(16.1488, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(16.1204, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(16.0922, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(16.0640, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(16.0358, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(16.0078, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(15.9797, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(15.9518, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(15.9239, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(15.8960, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(15.8682, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(15.8405, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(15.8128, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(15.7852, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(15.7577, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(15.7302, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(15.7027, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(15.6753, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(15.6480, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(15.6207, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(15.5935, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(15.5664, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(15.5392, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(15.5122, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(15.4852, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(15.4583, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(15.4314, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(15.4045, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(15.3778, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(15.3511, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(15.3244, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(15.2978, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(15.2712, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(15.2447, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(15.2183, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(15.1919, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(15.1656, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(15.1393, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(15.1131, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(15.0869, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(15.0608, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(15.0347, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(15.0087, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.9827, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.9568, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.9309, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.9051, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.8794, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.8537, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.8280, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.8024, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.7769, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.7514, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.7259, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.7005, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.6752, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.6499, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.6246, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.5995, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.5743, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.5492, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.5242, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.4992, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.4742, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.4493, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.4245, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.3997, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.3750, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.3503, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.3256, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.3010, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.2765, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.2520, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.2276, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.2032, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.1788, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.1545, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.1302, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.1060, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.0819, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.0577, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.0337, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(14.0096, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.9857, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.9617, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.9379, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.9140, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.8903, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.8666, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.8428, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.8192, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.7956, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.7720, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.7485, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.7251, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.7016, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.6783, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.6550, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.6317, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.6085, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.5853, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.5621, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.5390, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.5160, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.4930, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.4700, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.4471, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.4242, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.4014, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.3786, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.3559, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.3332, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.3105, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.2879, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.2654, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.2429, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.2204, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.1979, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.1755, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.1532, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.1309, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.1087, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.0864, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.0643, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.0421, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(13.0200, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.9980, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.9760, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.9541, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.9321, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.9103, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.8884, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.8666, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.8449, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.8232, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.8015, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.7799, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.7583, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.7367, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.7152, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.6938, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.6724, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.6510, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.6297, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.6084, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.5871, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.5659, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.5448, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.5236, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.5025, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.4815, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.4605, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.4395, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.4186, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.3977, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.3768, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.3560, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.3353, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.3145, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.2938, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.2732, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.2526, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.2320, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.2115, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.1910, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.1705, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.1501, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.1297, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.1094, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.0891, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.0688, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.0486, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.0284, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(12.0083, grad_fn=<DivBackward0>)\n",
            "loss:  tensor(11.9882, grad_fn=<DivBackward0>)\n",
            "---------------------------------------------\n",
            "loss:  tensor(11.9882, grad_fn=<DivBackward0>)\n",
            "---------------------------------------------\n",
            "new_prediction:  tensor([[ 58.2632,  71.4908],\n",
            "        [ 83.7415,  97.7705],\n",
            "        [114.9156, 138.5249],\n",
            "        [ 19.7005,  38.6016],\n",
            "        [105.1805, 113.1028]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y4LWNqmVeRKa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}