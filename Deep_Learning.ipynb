{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfAPNKWVtX2/23vAoQYz2R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaganFoundr/PyTorchNN/blob/main/Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LINEAR REGRESSION\n",
        "\n",
        "#importing all the important libraries\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "#inputs (temperature, rainfall, humidity)\n",
        "inputs=np.array([[73,67,45],\n",
        "                 [91,88,64],\n",
        "                 [87,134,58],\n",
        "                 [102,43,37],\n",
        "                 [69,96,70]],dtype='float32')\n",
        "\n",
        "#targets (apples, oranges)\n",
        "targets=np.array([[56,70],\n",
        "                 [81,101],\n",
        "                 [119,133],\n",
        "                 [22,37],\n",
        "                 [103,119]],dtype='float32')\n",
        "\n",
        "#converting inputs and targets from numpy format to tensor format\n",
        "inputs=torch.from_numpy(inputs)\n",
        "targets=torch.from_numpy(targets)\n",
        "\n",
        "# defining random weights and biases\n",
        "weights=torch.randn(2,3,requires_grad=True)\n",
        "bias=torch.randn(2,requires_grad=True)\n",
        "\n",
        "#function for the prediction equation for the model\n",
        "def model(x):\n",
        "  return x @ weights.t()+bias\n",
        "\n",
        "#function for the loss\n",
        "def mse(x,y):\n",
        "  diff=x-y\n",
        "  return torch.sum(diff*diff)/diff.numel()\n",
        "\n",
        "#training loop with 1000 epochs\n",
        "for i in range(1000):\n",
        "\n",
        "  #predicting using the inputs\n",
        "  prediction=model(inputs)\n",
        "\n",
        "  # checking the loss of the prediction\n",
        "  loss=mse(prediction, targets)\n",
        "  print(loss)\n",
        "\n",
        "  # backpropogating to compute gradients and update the weights\n",
        "  loss.backward()\n",
        "\n",
        "  #updating the weights without tracking the gradient\n",
        "  with torch.no_grad():\n",
        "\n",
        "    #learning rate value\n",
        "    lr=0.00001\n",
        "\n",
        "    #updating weights\n",
        "    weights-=weights.grad*lr\n",
        "\n",
        "    #updating bias\n",
        "    bias-=bias.grad*lr\n",
        "\n",
        "    #emptying the gradients of weights and bias\n",
        "    weights.grad.zero_()\n",
        "    bias.grad.zero_()\n",
        "\n",
        "print(loss)"
      ],
      "metadata": {
        "id": "CdEho-pTaSMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MORE COMPLEX LINEAR REGRESSION\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset,DataLoader\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "inputs=np.array([[73,67,43],[91,88,64],[87,134,58],\n",
        "                 [102,43,37],[69,96,70],[73,67,43],\n",
        "                 [91,88,64],[87,134,58],[102,43,37],\n",
        "                 [69,96,70],[73,67,43],[91,88,64],\n",
        "                 [87,134,58],[102,43,37],[69,96,70]],dtype='float32')\n",
        "\n",
        "targets=np.array([[56,70],[81,101],[119,133],\n",
        "                 [22,37],[103,119],[56,70],\n",
        "                 [81,101],[119,133],[22,37],\n",
        "                 [103,119],[56,70],[81,101],\n",
        "                 [119,133],[22,73],[103,119]],dtype='float32')\n",
        "\n",
        "inputs=torch.tensor(inputs)\n",
        "targets=torch.tensor(targets)\n",
        "\n",
        "training_data=TensorDataset(inputs,targets)\n",
        "\n",
        "batch_size = 5\n",
        "\n",
        "training_data=DataLoader(training_data, batch_size, shuffle=True )\n",
        "\n",
        "model=nn.Linear(3,2)\n",
        "\n",
        "list(model.parameters())\n",
        "\n",
        "loss_fn = F.mse_loss\n",
        "\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=0.00001)\n",
        "\n",
        "def train_function(nepochs, model, loss_fn, optimizer):\n",
        "  for epochs in range(nepochs):\n",
        "    for x,y in training_data:\n",
        "\n",
        "      prediction = model(x)\n",
        "\n",
        "      loss = loss_fn(prediction, y)\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "    if (epochs+1)%10==0:\n",
        "      print(f\"epochs: {epochs+1}/{nepochs} , loss: {loss.item()}\")\n",
        "\n",
        "train_function(1000, model, loss_fn, optimizer)\n",
        "\n",
        "prediction=model(inputs)\n",
        "\n",
        "print(prediction)\n",
        "\n",
        "print(targets)"
      ],
      "metadata": {
        "id": "ZJN2ACY-uplj",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LOGISTIC REGRESSION USING MNIST\n",
        "\n",
        "#importing libraries\n",
        "import torch\n",
        "from torchvision.datasets import MNIST\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import SubsetRandomSampler, DataLoader\n",
        "\n",
        "#main dataset and testdata\n",
        "dataset=MNIST(download=True, train=True, root=\"./data\", transform=transforms.ToTensor())\n",
        "testset=MNIST(root=\"./data\", train=False, transform=transforms.ToTensor())\n",
        "\n",
        "#plotting the dataset\n",
        "image,labels=dataset[1000]\n",
        "plt.imshow(image[0,10:25,10:25], cmap=\"gray\")\n",
        "plt.show()\n",
        "print(\"label: \", labels)"
      ],
      "metadata": {
        "id": "ZQV72q6kWpJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NHGGYphHtljA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting the whole dataset into validation data and training data\n",
        "def split_data(dataset, validation_percent):\n",
        "  validation_data=int(dataset*validation_percent)\n",
        "  shuffled=np.random.permutation(dataset)\n",
        "  return shuffled[validation_data:], shuffled[:validation_data]\n",
        "\n",
        "training_data,validation_data = split_data(len(dataset), 0.3)\n",
        "print(\"length of training data: \", len(training_data))\n",
        "print(\"length of validation data: \", len(validation_data))\n",
        "\n",
        "print(\"portion of validation data: \",validation_data[:20])"
      ],
      "metadata": {
        "id": "dlorU70oXLps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#putting all the splitted data to the sampler and then into the dataloader\n",
        "train_data_sampler=SubsetRandomSampler(training_data)\n",
        "valid_data_sampler=SubsetRandomSampler(validation_data)\n",
        "\n",
        "batch_size=100\n",
        "\n",
        "training_loader=DataLoader(dataset, batch_size, sampler=train_data_sampler)\n",
        "validation_loader=DataLoader(dataset, batch_size, sampler=valid_data_sampler)"
      ],
      "metadata": {
        "id": "JIlbxkGddWAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the model\n",
        "input_size=28*28\n",
        "num_classes=10\n",
        "\n",
        "class MNISTmodel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.Linear=nn.Linear(input_size,num_classes)\n",
        "\n",
        "  def forward(self, size):\n",
        "    size=size.reshape(-1,784)\n",
        "    output=self.Linear(size)\n",
        "    return output\n",
        "\n",
        "model=MNISTmodel()"
      ],
      "metadata": {
        "id": "3Gej-4W87N2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#putting the training loader in the for loop as inputs and outputs for prediction\n",
        "for images, labels in training_loader:\n",
        "  prediction=model(images)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "zZXbi9a5Pv87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#display predictions and sum of the predictions of each array\n",
        "print(prediction[:2])\n",
        "sum=torch.sum(prediction[2])\n",
        "print(sum)\n",
        "\n",
        "#changing the sum of the probablities of the predictions close to 1 and then checking the sum again\n",
        "prob=F.softmax(prediction)\n",
        "print(prob[:2])\n",
        "sum=torch.sum(prob[2])\n",
        "print(sum)\n",
        "\n",
        "#displaying the exact predicted labels by the model\n",
        "max_prob, pred = torch.max(prob, dim=1)\n",
        "print(pred)\n",
        "print(max_prob)\n",
        "\n",
        "#displaying the actual target labels\n",
        "print(labels)"
      ],
      "metadata": {
        "id": "XGqPcJUW9P4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the loss\n",
        "loss_fn=F.cross_entropy"
      ],
      "metadata": {
        "id": "ivMZt7kCgQQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the optimizer\n",
        "opt=torch.optim.SGD(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "iDN3RG9YjUEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy metrics\n",
        "def accuracy(outputs, labels):\n",
        "  _,pred=torch.max(outputs, dim=1)\n",
        "  return (torch.sum(pred==labels).item()/len(pred))*100"
      ],
      "metadata": {
        "id": "bSGzZGi4S59k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss batch function for loss computation, gradient computation, updating weights, resetting gradients, accuracy computation\n",
        "def loss_batch(model, loss_fn, images, labels, opt, metrics=accuracy):\n",
        "  prediction=model(images)\n",
        "  loss=loss_fn(prediction, labels)\n",
        "\n",
        "  if opt is not None:\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "\n",
        "  metric_result=None\n",
        "  if metrics is not None:\n",
        "    metric_result=metrics(prediction, labels)\n",
        "\n",
        "  return loss.item(), len(images), metric_result"
      ],
      "metadata": {
        "id": "oObTH91hPsnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for evaluating the average loss and average accuracy of the validation set\n",
        "def evaluate(model, loss_fn, validation_loader, metrics=accuracy):\n",
        "  with torch.no_grad():\n",
        "    validation_prediction=[loss_batch(model, loss_fn, images, labels, opt=None, metrics=accuracy) for images, labels in validation_loader]\n",
        "\n",
        "    losses, nums, metric=zip(*validation_prediction)\n",
        "\n",
        "    total=np.sum(nums)\n",
        "\n",
        "    average_loss = np.sum(np.multiply(losses, nums))/total\n",
        "\n",
        "    average_metrics=None\n",
        "    if metrics is not None:\n",
        "      average_metrics = np.sum(np.multiply(metric, nums))/total\n",
        "\n",
        "  return average_loss.item(), total, average_metrics"
      ],
      "metadata": {
        "id": "OkoWI6TfbQyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function for explicit training\n",
        "def fit(nepochs, model, images, labels, training_loader, validation_loader, opt, metrics=accuracy):\n",
        "  for epoch in range(nepochs):\n",
        "    for images, labels in training_loader:\n",
        "      train_loss,_, train_accuracy=loss_batch(model, loss_fn, images, labels, opt, metrics=accuracy)\n",
        "\n",
        "    valid_loss, _, valid_accuracy= evaluate(model, loss_fn, validation_loader, metrics=accuracy)\n",
        "\n",
        "    print(f\"Epoch: {epoch+1}/{nepochs}\")\n",
        "    print(f\"Training loss: {train_loss:.4f} and Validation loss: {valid_loss:.4f}.\")\n",
        "    print(f\"Training accuracy: {train_accuracy:.2f}% and Validation accuracy: {valid_accuracy:.2f}%.\")\n",
        "    print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "  return train_loss, _, train_accuracy, valid_loss, _, valid_accuracy\n",
        "\n",
        "train_loss,_, train_accuracy, valid_loss, _, valid_accuracy = fit(6, model, images, labels, training_loader, validation_loader, opt, metrics=accuracy)\n",
        "\n",
        "print(\"--\")\n",
        "print(f\"The train accuracy is {train_accuracy:.2f} % and loss is {train_loss:.4f}.\")\n",
        "print(\"--------------------------------------------\")\n",
        "print(f\"The validation accuracy is {valid_accuracy:.2f} % and loss is {valid_loss:.4f}\")"
      ],
      "metadata": {
        "id": "TCttIo85b4ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing the model with the testing dataset\n",
        "#function for predicting the test images\n",
        "def predict_image(image, model):\n",
        "  input=image.unsqueeze(0)\n",
        "  output=model(input)\n",
        "  _,preds=torch.max(output, dim=1)\n",
        "\n",
        "  return preds[0].item()"
      ],
      "metadata": {
        "id": "v8W1V8lqiu3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predicting and displaying different labels\n",
        "image,labels=testset[10]\n",
        "plt.imshow(image[0], cmap=\"gray\")\n",
        "plt.show()\n",
        "print(\"label: \", labels)\n",
        "print(\"predicted: \", predict_image(image, model))\n",
        "\n",
        "image,labels=testset[100]\n",
        "plt.imshow(image[0], cmap=\"gray\")\n",
        "plt.show()\n",
        "print(\"label: \", labels)\n",
        "print(\"predicted: \", predict_image(image, model))\n",
        "\n",
        "image,labels=testset[1000]\n",
        "plt.imshow(image[0], cmap=\"gray\")\n",
        "plt.show()\n",
        "print(\"label: \", labels)\n",
        "print(\"predicted: \", predict_image(image, model))\n",
        "\n",
        "image,labels=testset[905]\n",
        "plt.imshow(image[0], cmap=\"gray\")\n",
        "plt.show()\n",
        "print(\"label: \", labels)\n",
        "print(\"predicted: \", predict_image(image, model))"
      ],
      "metadata": {
        "id": "rmP4znRwkh7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the loss and accuracy on the test set\n",
        "test_loader=DataLoader(testset, batch_size=200)\n",
        "test_loss, total, test_accuracy=evaluate(model, loss_fn, test_loader, metrics=accuracy)\n",
        "print(f\"The test set loss is {test_loss:.4f} and the accuracy is {test_accuracy:.2f}%.\")"
      ],
      "metadata": {
        "id": "xCKU1FQKn-YG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#saving and loading the model\n",
        "torch.save(model.state_dict(),'MNISTlogistic.pth')\n",
        "model.state_dict()"
      ],
      "metadata": {
        "id": "ILIq6GWqqLFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "savedmodel=MNISTmodel()\n",
        "savedmodel.load_state_dict(torch.load('MNISTlogistic.pth'))\n",
        "savedmodel.state_dict()"
      ],
      "metadata": {
        "id": "9s_BDeUdr7ZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jNhqtZ1sYjVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UPQfPo9TYjST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1\n",
        "import torch\n",
        "from torchvision.datasets import MNIST\n",
        "import torchvision.transforms as transform\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch.utils.data import SubsetRandomSampler, DataLoader"
      ],
      "metadata": {
        "id": "wu3GnbgisZBY"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2\n",
        "dataset=MNIST(root='./data', download=True, train=True, transform=transform.ToTensor())\n",
        "testset=MNIST(root='./data', download=True, train=False, transform=transform.ToTensor())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shgd51IfVTNH",
        "outputId": "79b50f1d-7e9a-418b-88c8-a80a9c45c674"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 17.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 495kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.49MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 2.76MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3\n",
        "images, labels = dataset[230]\n",
        "plot=images[:,10:17,10:17]\n",
        "plt.imshow(plot[0], cmap='gray')\n",
        "plt.show()\n",
        "print(\"labels: \",labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "YXJRiX_MYaF5",
        "outputId": "ed06ddde-b113-4b2a-e771-b82331b15368"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAGdCAYAAAAv9mXmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAWm0lEQVR4nO3df2xV9f348deFrhfEtvwQkI5SNf5ARJhSYQzdpjINUaL+4YzBjDGzRFKmSEwM/wyXZZYlm9FtBMVt6pIx3BZRZ4KMMYEYZfIjJKiJirJYRUAX7C1dcjH0fv9Y7Gd8FcZt77uHWx+P5CTek/fpeV2CfXLu6b3NlUqlUgBAhQ3KegAABiaBASAJgQEgCYEBIAmBASAJgQEgCYEBIAmBASCJmv4+YXd3d+zbty/q6uoil8v19+kB6INSqRSdnZ3R2NgYgwad+Bql3wOzb9++aGpq6u/TAlBB7e3tMX78+BOu6ffA1NXVRUTE7373uzjttNP6+/TJ3H777VmPUHEdHR1ZjwCcoj79Xn4i/R6YT18WO+200wZUYLzcB3yRnMz3PDf5AUhCYABIQmAASEJgAEhCYABIQmAASEJgAEhCYABIQmAASEJgAEhCYABIQmAASEJgAEhCYABIQmAASEJgAEhCYABIQmAASEJgAEiiV4FZsWJFnHXWWTFkyJCYMWNGvPLKK5WeC4AqV3ZgnnzyyViyZEksW7Ysdu7cGVOnTo1rr702Dh48mGI+AKpU2YF54IEH4vvf/34sWLAgJk2aFA8//HCcdtpp8dvf/jbFfABUqbICc+TIkdixY0fMnj37/77AoEExe/bsePnllz/3mGKxGIVC4ZgNgIGvrMB89NFHcfTo0Rg7duwx+8eOHRv79+//3GPa2tqioaGhZ2tqaur9tABUjeQ/RbZ06dLo6Ojo2drb21OfEoBTQE05i88444wYPHhwHDhw4Jj9Bw4ciDPPPPNzj8nn85HP53s/IQBVqawrmNra2pg2bVps3LixZ193d3ds3LgxZs6cWfHhAKheZV3BREQsWbIk5s+fHy0tLTF9+vR48MEHo6urKxYsWJBiPgCqVNmBueWWW+LDDz+MH/7wh7F///74yle+Es8///xnbvwD8MVWdmAiIhYtWhSLFi2q9CwADCA+iwyAJAQGgCQEBoAkBAaAJAQGgCQEBoAkBAaAJAQGgCQEBoAkBAaAJAQGgCQEBoAkBAaAJAQGgCQEBoAkBAaAJAQGgCQEBoAkBAaAJHKlUqnUnycsFArR0NAQw4cPj1wu15+nTurQoUNZjwDQbzo6OqK+vv6Ea1zBAJCEwACQhMAAkITAAJCEwACQhMAAkITAAJCEwACQhMAAkITAAJCEwACQhMAAkITAAJCEwACQhMAAkITAAJCEwACQhMAAkITAAJCEwACQhMAAkITAAJBE2YHZsmVLzJ07NxobGyOXy8XTTz+dYCwAql3Zgenq6oqpU6fGihUrUswDwABRU+4Bc+bMiTlz5qSYBYABpOzAlKtYLEaxWOx5XCgUUp8SgFNA8pv8bW1t0dDQ0LM1NTWlPiUAp4DkgVm6dGl0dHT0bO3t7alPCcApIPlLZPl8PvL5fOrTAHCK8T4YAJIo+wrm8OHDsWfPnp7He/fujV27dsXIkSNjwoQJFR0OgOqVK5VKpXIO2LRpU1x55ZWf2T9//vx4/PHH/+fxhUIhGhoaYvjw4ZHL5co59Snt0KFDWY8A0G86Ojqivr7+hGvKvoL55je/GWU2CYAvIPdgAEhCYABIQmAASEJgAEhCYABIQmAASEJgAEhCYABIQmAASEJgAEhCYABIQmAASEJgAEhCYABIQmAASEJgAEhCYABIQmAASEJgAEiiJqsTf/zxx1mdGqBf5fP5rEeomFKpFEeOHDmpta5gAEhCYABIQmAASEJgAEhCYABIQmAASEJgAEhCYABIQmAASEJgAEhCYABIQmAASEJgAEhCYABIQmAASEJgAEhCYABIQmAASEJgAEhCYABIQmAASEJgAEiirMC0tbXFZZddFnV1dTFmzJi48cYb44033kg1GwBVrKzAbN68OVpbW2Pr1q2xYcOG+OSTT+Kaa66Jrq6uVPMBUKVypVKp1NuDP/zwwxgzZkxs3rw5vv71r5/UMYVCIRoaGnp7SoCqk8/nsx6hYkqlUhw5ciQ6Ojqivr7+hGtr+nKijo6OiIgYOXLkcdcUi8UoFos9jwuFQl9OCUCV6PVN/u7u7li8eHHMmjUrJk+efNx1bW1t0dDQ0LM1NTX19pQAVJFev0S2cOHCWLduXbz44osxfvz44677vCsYkQG+SLxEVoZFixbFc889F1u2bDlhXCL+8wc7kP5wATg5ZQWmVCrFD37wg1i7dm1s2rQpzj777FRzAVDlygpMa2trrF69Op555pmoq6uL/fv3R0REQ0NDDB06NMmAAFSnsu7B5HK5z93/2GOPxXe/+92T+hp+TBn4ohlItwmS3YPpw1tmAPiC8VlkACQhMAAkITAAJCEwACQhMAAkITAAJCEwACQhMAAkITAAJCEwACQhMAAkITAAJCEwACQhMAAkITAAJCEwACQhMAAkITAAJFHWr0wGoHz33HNP1iNUTLFYjJ/97GcntdYVDABJCAwASQgMAEkIDABJCAwASQgMAEkIDABJCAwASQgMAEkIDABJCAwASQgMAEkIDABJCAwASQgMAEkIDABJCAwASQgMAEkIDABJCAwASQgMAEkIDABJlBWYlStXxpQpU6K+vj7q6+tj5syZsW7dulSzAVDFygrM+PHjY/ny5bFjx47Yvn17XHXVVXHDDTfEa6+9lmo+AKpUTTmL586de8zjn/zkJ7Fy5crYunVrXHTRRRUdDIDqVlZg/tvRo0fjT3/6U3R1dcXMmTOPu65YLEaxWOx5XCgUentKAKpI2Tf5d+/eHaeffnrk8/m44447Yu3atTFp0qTjrm9ra4uGhoaerampqU8DA1Adyg7MBRdcELt27Yp//OMfsXDhwpg/f368/vrrx12/dOnS6Ojo6Nna29v7NDAA1aHsl8hqa2vj3HPPjYiIadOmxbZt2+Khhx6KRx555HPX5/P5yOfzfZsSgKrT5/fBdHd3H3OPBQAiyryCWbp0acyZMycmTJgQnZ2dsXr16ti0aVOsX78+1XwAVKmyAnPw4MH4zne+Ex988EE0NDTElClTYv369fGtb30r1XwAVKmyAvOb3/wm1RwADDA+iwyAJAQGgCQEBoAkBAaAJAQGgCQEBoAkBAaAJAQGgCQEBoAkBAaAJAQGgCQEBoAkBAaAJAQGgCQEBoAkBAaAJAQGgCQEBoAkBAaAJHKlUqnUnycsFArR0NDQn6cEqshXv/rVrEeouHXr1mU9QsUUCoVobm6Ojo6OqK+vP+FaVzAAJCEwACQhMAAkITAAJCEwACQhMAAkITAAJCEwACQhMAAkITAAJCEwACQhMAAkITAAJCEwACQhMAAkITAAJCEwACQhMAAkITAAJCEwACQhMAAkITAAJNGnwCxfvjxyuVwsXry4QuMAMFD0OjDbtm2LRx55JKZMmVLJeQAYIHoVmMOHD8e8efPi0UcfjREjRlR6JgAGgF4FprW1Na677rqYPXv2/1xbLBajUCgcswEw8NWUe8CaNWti586dsW3btpNa39bWFj/60Y/KHgyA6lbWFUx7e3vcdddd8fvf/z6GDBlyUscsXbo0Ojo6erb29vZeDQpAdSnrCmbHjh1x8ODBuPTSS3v2HT16NLZs2RK/+tWvolgsxuDBg485Jp/PRz6fr8y0AFSNsgJz9dVXx+7du4/Zt2DBgpg4cWLce++9n4kLAF9cZQWmrq4uJk+efMy+YcOGxahRoz6zH4AvNu/kByCJsn+K7P+3adOmCowBwEDjCgaAJAQGgCQEBoAkBAaAJAQGgCQEBoAkBAaAJAQGgCQEBoAkBAaAJAQGgCQEBoAkBAaAJAQGgCQEBoAkBAaAJAQGgCQEBoAkBAaAJGqyHgDgv23YsCHrESpu2LBhWY9QMblc7qTXuoIBIAmBASAJgQEgCYEBIAmBASAJgQEgCYEBIAmBASAJgQEgCYEBIAmBASAJgQEgCYEBIAmBASAJgQEgCYEBIAmBASAJgQEgCYEBIAmBASAJgQEgCYEBIImyAnPfffdFLpc7Zps4cWKq2QCoYjXlHnDRRRfF3/72t//7AjVlfwkAvgDKrkNNTU2ceeaZKWYBYAAp+x7MW2+9FY2NjXHOOefEvHnz4t133z3h+mKxGIVC4ZgNgIGvrMDMmDEjHn/88Xj++edj5cqVsXfv3rjiiiuis7PzuMe0tbVFQ0NDz9bU1NTnoQE49eVKpVKptwd//PHH0dzcHA888EDcfvvtn7umWCxGsVjseVwoFEQGOK4T/YO1Wg0bNizrESqmUCjE8OHDo6OjI+rr60+4tk936IcPHx7nn39+7Nmz57hr8vl85PP5vpwGgCrUp/fBHD58ON5+++0YN25cpeYBYIAoKzD33HNPbN68Of75z3/GSy+9FDfddFMMHjw4br311lTzAVClynqJ7L333otbb701/vWvf8Xo0aPj8ssvj61bt8bo0aNTzQdAlSorMGvWrEk1BwADjM8iAyAJgQEgCYEBIAmBASAJgQEgCYEBIAmBASAJgQEgCYEBIAmBASAJgQEgCYEBIAmBASAJgQEgCYEBIAmBASAJgQEgCYEBIAmBASCJmqwHAHrvqaeeynqEijv99NOzHqHiOjs7sx6hYg4fPnzSa13BAJCEwACQhMAAkITAAJCEwACQhMAAkITAAJCEwACQhMAAkITAAJCEwACQhMAAkITAAJCEwACQhMAAkITAAJCEwACQhMAAkITAAJCEwACQhMAAkITAAJBE2YF5//3347bbbotRo0bF0KFD4+KLL47t27enmA2AKlZTzuJDhw7FrFmz4sorr4x169bF6NGj46233ooRI0akmg+AKlVWYH76059GU1NTPPbYYz37zj777IoPBUD1K+slsmeffTZaWlri5ptvjjFjxsQll1wSjz766AmPKRaLUSgUjtkAGPjKCsw777wTK1eujPPOOy/Wr18fCxcujDvvvDOeeOKJ4x7T1tYWDQ0NPVtTU1Ofhwbg1JcrlUqlk11cW1sbLS0t8dJLL/Xsu/POO2Pbtm3x8ssvf+4xxWIxisViz+NCoSAyUCFPPfVU1iNU3E033ZT1CBXX2dmZ9QgVUygUYvz48dHR0RH19fUnXFvWFcy4ceNi0qRJx+y78MIL49133z3uMfl8Purr64/ZABj4ygrMrFmz4o033jhm35tvvhnNzc0VHQqA6ldWYO6+++7YunVr3H///bFnz55YvXp1rFq1KlpbW1PNB0CVKiswl112Waxduzb+8Ic/xOTJk+PHP/5xPPjggzFv3rxU8wFQpcp6H0xExPXXXx/XX399ilkAGEB8FhkASQgMAEkIDABJCAwASQgMAEkIDABJCAwASQgMAEkIDABJCAwASQgMAEkIDABJCAwASQgMAEkIDABJCAwASQgMAEkIDABJlP0rk/uqVCr19ylhwPr3v/+d9QgVVygUsh6h4jo7O7MeoWI+fS4n8708V+rn7/jvvfdeNDU19ecpAaiw9vb2GD9+/AnX9Htguru7Y9++fVFXVxe5XC7ZeQqFQjQ1NUV7e3vU19cnO09/8pxOfQPt+UR4TtWiv55TqVSKzs7OaGxsjEGDTnyXpd9fIhs0aND/rF4l1dfXD5i/QJ/ynE59A+35RHhO1aI/nlNDQ8NJrXOTH4AkBAaAJAZsYPL5fCxbtizy+XzWo1SM53TqG2jPJ8Jzqhan4nPq95v8AHwxDNgrGACyJTAAJCEwACQhMAAkMSADs2LFijjrrLNiyJAhMWPGjHjllVeyHqlPtmzZEnPnzo3GxsbI5XLx9NNPZz1Sn7S1tcVll10WdXV1MWbMmLjxxhvjjTfeyHqsPlm5cmVMmTKl501uM2fOjHXr1mU9VkUtX748crlcLF68OOtReu2+++6LXC53zDZx4sSsx+qT999/P2677bYYNWpUDB06NC6++OLYvn171mNFxAAMzJNPPhlLliyJZcuWxc6dO2Pq1Klx7bXXxsGDB7Merde6urpi6tSpsWLFiqxHqYjNmzdHa2trbN26NTZs2BCffPJJXHPNNdHV1ZX1aL02fvz4WL58eezYsSO2b98eV111Vdxwww3x2muvZT1aRWzbti0eeeSRmDJlStaj9NlFF10UH3zwQc/24osvZj1Srx06dChmzZoVX/rSl2LdunXx+uuvx89//vMYMWJE1qP9R2mAmT59eqm1tbXn8dGjR0uNjY2ltra2DKeqnIgorV27NusxKurgwYOliCht3rw561EqasSIEaVf//rXWY/RZ52dnaXzzjuvtGHDhtI3vvGN0l133ZX1SL22bNmy0tSpU7Meo2Luvffe0uWXX571GMc1oK5gjhw5Ejt27IjZs2f37Bs0aFDMnj07Xn755Qwn40Q6OjoiImLkyJEZT1IZR48ejTVr1kRXV1fMnDkz63H6rLW1Na677rpj/r+qZm+99VY0NjbGOeecE/PmzYt3330365F67dlnn42Wlpa4+eabY8yYMXHJJZfEo48+mvVYPQZUYD766KM4evRojB079pj9Y8eOjf3792c0FSfS3d0dixcvjlmzZsXkyZOzHqdPdu/eHaeffnrk8/m44447Yu3atTFp0qSsx+qTNWvWxM6dO6OtrS3rUSpixowZ8fjjj8fzzz8fK1eujL1798YVV1xRtb+v5Z133omVK1fGeeedF+vXr4+FCxfGnXfeGU888UTWo0VEBp+mDP+ttbU1Xn311ap+HfxTF1xwQezatSs6Ojriz3/+c8yfPz82b95ctZFpb2+Pu+66KzZs2BBDhgzJepyKmDNnTs9/T5kyJWbMmBHNzc3xxz/+MW6//fYMJ+ud7u7uaGlpifvvvz8iIi655JJ49dVX4+GHH4758+dnPN0Au4I544wzYvDgwXHgwIFj9h84cCDOPPPMjKbieBYtWhTPPfdcvPDCC/36KxxSqa2tjXPPPTemTZsWbW1tMXXq1HjooYeyHqvXduzYEQcPHoxLL700ampqoqamJjZv3hy/+MUvoqamJo4ePZr1iH02fPjwOP/882PPnj1Zj9Ir48aN+8w/YC688MJT5mW/ARWY2tramDZtWmzcuLFnX3d3d2zcuHFAvBY+UJRKpVi0aFGsXbs2/v73v8fZZ5+d9UhJdHd3R7FYzHqMXrv66qtj9+7dsWvXrp6tpaUl5s2bF7t27YrBgwdnPWKfHT58ON5+++0YN25c1qP0yqxZsz7zI/5vvvlmNDc3ZzTRsQbcS2RLliyJ+fPnR0tLS0yfPj0efPDB6OrqigULFmQ9Wq8dPnz4mH9h7d27N3bt2hUjR46MCRMmZDhZ77S2tsbq1avjmWeeibq6up77Yw0NDTF06NCMp+udpUuXxpw5c2LChAnR2dkZq1evjk2bNsX69euzHq3X6urqPnNfbNiwYTFq1KiqvV92zz33xNy5c6O5uTn27dsXy5Yti8GDB8ett96a9Wi9cvfdd8fXvva1uP/+++Pb3/52vPLKK7Fq1apYtWpV1qP9R9Y/xpbCL3/5y9KECRNKtbW1penTp5e2bt2a9Uh98sILL5Qi4jPb/Pnzsx6tVz7vuURE6bHHHst6tF773ve+V2pubi7V1taWRo8eXbr66qtLf/3rX7Meq+Kq/ceUb7nlltK4ceNKtbW1pS9/+culW265pbRnz56sx+qTv/zlL6XJkyeX8vl8aeLEiaVVq1ZlPVIPH9cPQBID6h4MAKcOgQEgCYEBIAmBASAJgQEgCYEBIAmBASAJgQEgCYEBIAmBASAJgQEgCYEBIIn/B3N4Vfy9HUM5AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels:  7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4\n",
        "def splitted_data(data, valid_data_percent):\n",
        "  valid_num=int(data*valid_data_percent)\n",
        "  index=np.random.permutation(data)\n",
        "  return index[valid_num:], index[:valid_num]\n",
        "training_data, validation_data=splitted_data(len(dataset), 0.25)\n",
        "print(\"Training data: \",len(training_data))\n",
        "print(\"Validation data\",len(validation_data))\n",
        "print(\"portion of validation data: \", validation_data[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjY91nW4YZ3Z",
        "outputId": "e21830e8-bdfd-4bce-da87-36a3f5f01881"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data:  45000\n",
            "Validation data 15000\n",
            "portion of validation data:  [31574  4676 45976 17191 49237 11063  6707 12573 45091  7472 25482 40707\n",
            " 37330 50627 40905  6364 41302 34121 58774 45092]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5\n",
        "training_sampler=SubsetRandomSampler(training_data)\n",
        "validation_sampler=SubsetRandomSampler(validation_data)\n",
        "\n",
        "batch_size=100\n",
        "\n",
        "training_loader=DataLoader(dataset=dataset, batch_size=batch_size, sampler=training_sampler)\n",
        "validation_loader=DataLoader(dataset=dataset, batch_size=batch_size, sampler=validation_sampler)"
      ],
      "metadata": {
        "id": "1c2jumtnYZ0s"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6\n",
        "input_size=28*28\n",
        "hidden_size1=256\n",
        "hidden_size2=128\n",
        "output_size=10\n",
        "class MNISTMODEL(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size1, hidden_size2 ,output_size):\n",
        "    super().__init__()\n",
        "    #hidden layer1\n",
        "    self.linear1=nn.Linear(input_size, hidden_size1)\n",
        "    #hidden layer2\n",
        "    self.linear2=nn.Linear(hidden_size1, hidden_size2)\n",
        "    #output layer\n",
        "    self.linear3=nn.Linear(hidden_size2, output_size)\n",
        "\n",
        "\n",
        "  def forward(self,batch):\n",
        "    size=batch.view(batch.size(0),-1)\n",
        "\n",
        "    hidden1=self.linear1(size)\n",
        "\n",
        "    output=F.relu(hidden1)\n",
        "\n",
        "    hidden2=self.linear2(output)\n",
        "\n",
        "    output=F.relu(hidden2)\n",
        "\n",
        "    output=self.linear3(output)\n",
        "\n",
        "    return output\n",
        "\n",
        "model=MNISTMODEL(input_size, hidden_size1, hidden_size2, output_size)"
      ],
      "metadata": {
        "id": "zlKTAD2HYZyT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for t in model.parameters():\n",
        "  print(t.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7M5CWRypoUj6",
        "outputId": "34d06256-7045-4f0a-e5e5-574ed2454047"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 784])\n",
            "torch.Size([256])\n",
            "torch.Size([128, 256])\n",
            "torch.Size([128])\n",
            "torch.Size([10, 128])\n",
            "torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#7\n",
        "for images, labels in training_loader:\n",
        "  prediction=model(images)"
      ],
      "metadata": {
        "id": "4vmTOP1aYZue"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8\n",
        "print(prediction[0])\n",
        "\n",
        "#9\n",
        "prob_sum=torch.sum(prediction[0])\n",
        "print(prob_sum)\n",
        "\n",
        "changed_pred=F.softmax(prediction)\n",
        "changed_sum=torch.sum(changed_pred[9])\n",
        "print(changed_sum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26sKMZg6YZjv",
        "outputId": "4e9fe89a-bee4-4bbf-8321-8238ff3a8e51"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.0028,  0.0997,  0.0757,  0.0355, -0.0532, -0.0093,  0.0070,  0.0064,\n",
            "        -0.0342, -0.0549], grad_fn=<SelectBackward0>)\n",
            "tensor(0.0756, grad_fn=<SumBackward0>)\n",
            "tensor(1.0000, grad_fn=<SumBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-a0f466636ccd>:8: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  changed_pred=F.softmax(prediction)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#10\n",
        "_,pred=torch.max(prediction, dim=1)\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8PPAvBlgqZA",
        "outputId": "3604c32d-6b32-4e05-8ac6-5d984e638e59"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 1, 2, 2, 2, 1, 2, 2, 6, 1, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 2, 1, 2,\n",
            "        1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 1,\n",
            "        2, 1, 2, 2, 2, 1, 2, 2, 1, 1, 2, 1, 2, 1, 2, 2, 1, 2, 1, 2, 2, 2, 1, 2,\n",
            "        1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2,\n",
            "        1, 2, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#11\n",
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ydw4qipQgqRs",
        "outputId": "02097d4e-5977-476d-9c17-e465ed044623"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 8, 9, 2, 4, 6, 0, 8, 4, 2, 8, 0, 4, 1, 3, 5, 7, 7, 7, 0, 4, 8, 1, 9,\n",
              "        1, 7, 6, 1, 1, 4, 4, 9, 8, 1, 7, 4, 1, 8, 3, 9, 1, 0, 8, 5, 9, 9, 6, 3,\n",
              "        4, 5, 0, 7, 6, 3, 5, 2, 8, 1, 4, 1, 6, 1, 7, 5, 7, 2, 6, 8, 4, 6, 7, 3,\n",
              "        3, 8, 9, 6, 6, 9, 6, 9, 1, 0, 9, 6, 0, 1, 8, 9, 7, 7, 4, 6, 4, 2, 2, 2,\n",
              "        7, 9, 8, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#12\n",
        "def accuracy(output, labels):\n",
        "  _,pred=torch.max(output, dim=1)\n",
        "  return torch.sum(pred==labels).item()/len(pred)*100"
      ],
      "metadata": {
        "id": "AYn7pl5AYZaC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#13\n",
        "loss_function=F.cross_entropy"
      ],
      "metadata": {
        "id": "whNpBd-Vfcy3"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#14\n",
        "opt=torch.optim.SGD(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "5OhakYczfcwQ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#15\n",
        "def loss_batch(model, loss_function, images, labels, opt, metrics=accuracy):\n",
        "  prediction=model(images)\n",
        "  loss=loss_function(prediction, labels)\n",
        "\n",
        "  if opt is not None:\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "\n",
        "  metric_result=None\n",
        "  if metrics is not None:\n",
        "    metric_result=metrics(prediction, labels)\n",
        "\n",
        "  return loss.item(), len(images), metric_result"
      ],
      "metadata": {
        "id": "j0su4yJQfct6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#16\n",
        "def evaluate(model, loss_function, validation_loader, metrics=accuracy):\n",
        "  with torch.no_grad():\n",
        "    result=[loss_batch(model, loss_function, images, labels, opt=None, metrics=accuracy) for images, labels in validation_loader]\n",
        "\n",
        "    losses, num, metric=zip(*result)\n",
        "\n",
        "    total=np.sum(num)\n",
        "\n",
        "    loss=np.sum(np.multiply(losses, num))/total\n",
        "\n",
        "    if metrics is not None:\n",
        "      metric=np.sum(np.multiply(metric, num))/total\n",
        "  return loss, total, metric"
      ],
      "metadata": {
        "id": "3mu76XCEfcrj"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#17\n",
        "def train(nepochs, model, loss_function, training_loader, validation_loader, images, labels, opt, metrics=accuracy):\n",
        "  for epoch in range(nepochs):\n",
        "    for images, labels in training_loader:\n",
        "      train_loss,_,train_acc=loss_batch(model, loss_function, images, labels, opt, metrics=accuracy)\n",
        "\n",
        "    valid_loss,_,valid_acc=evaluate(model, loss_function, validation_loader, metrics=accuracy)\n",
        "\n",
        "    print(f\"Epoch: {epoch+1}/{nepochs}\")\n",
        "    print(f\"Training loss: {train_loss:.4f} and Validation loss: {valid_loss:.4f}.\")\n",
        "    print(f\"Training accuracy: {train_acc:.2f}% and Validation accuracy: {valid_acc:.2f}%.\")\n",
        "    print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "  return train_loss,train_acc, valid_loss,valid_acc\n",
        "\n",
        "train_loss, train_acc, valid_loss, valid_acc = train(6, model, loss_function, training_loader, validation_loader, images, labels, opt, metrics=accuracy)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MI5bHKeEfco7",
        "outputId": "f0641f56-e761-4926-a71c-2efd77320d50"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/6\n",
            "Training loss: 1.7843 and Validation loss: 1.8035.\n",
            "Training accuracy: 64.00% and Validation accuracy: 62.03%.\n",
            "--------------------------------------------------------------------------------------------\n",
            "Epoch: 2/6\n",
            "Training loss: 0.7134 and Validation loss: 0.8134.\n",
            "Training accuracy: 80.00% and Validation accuracy: 79.97%.\n",
            "--------------------------------------------------------------------------------------------\n",
            "Epoch: 3/6\n",
            "Training loss: 0.5364 and Validation loss: 0.5522.\n",
            "Training accuracy: 86.00% and Validation accuracy: 85.15%.\n",
            "--------------------------------------------------------------------------------------------\n",
            "Epoch: 4/6\n",
            "Training loss: 0.5750 and Validation loss: 0.4553.\n",
            "Training accuracy: 81.00% and Validation accuracy: 87.42%.\n",
            "--------------------------------------------------------------------------------------------\n",
            "Epoch: 5/6\n",
            "Training loss: 0.4558 and Validation loss: 0.4035.\n",
            "Training accuracy: 90.00% and Validation accuracy: 88.64%.\n",
            "--------------------------------------------------------------------------------------------\n",
            "Epoch: 6/6\n",
            "Training loss: 0.3643 and Validation loss: 0.3733.\n",
            "Training accuracy: 91.00% and Validation accuracy: 89.44%.\n",
            "--------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#18\n",
        "def prediction(images, model):\n",
        "  input=images.unsqueeze(0)\n",
        "  output=model(input)\n",
        "  _,pred=torch.max(output, dim=1)\n",
        "\n",
        "  return pred[0].item()"
      ],
      "metadata": {
        "id": "cZ2_ceTcfcmZ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#19\n",
        "images, labels=testset[20]\n",
        "plt.imshow(images[0], cmap='gray')\n",
        "plt.show()\n",
        "print(\"labels: \", labels)\n",
        "print(\"predicted: \",prediction(images, model))\n",
        "\n",
        "test_loader=DataLoader(testset, batch_size=200)\n",
        "\n",
        "\n",
        "#test accuracy (you define it in your own form)\n",
        "print(evaluate(model, loss_function, test_loader, metrics=accuracy))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "CfzFPJNqfcjs",
        "outputId": "3ac11fdf-becf-455f-91cb-1a32cc4cf5b4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbhUlEQVR4nO3df2xV9f3H8VcL9ILS3q6W9rZSakEFIz8WGdQGZW50tHVjovzhr2RlcTDdhYmd03RREbelkyVq3DpMFkc1EXUkAlEzMqy2xK1gQElDNhvadRZDWyYb95YiBdvP9w/i/XqlgOdyb9+9l+cjOQm997573x5veHLb29s055wTAAAjLN16AQDAxYkAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE2OtF/iyoaEhHTp0SJmZmUpLS7NeBwDgkXNOfX19KiwsVHr62Z/njLoAHTp0SEVFRdZrAAAu0MGDBzV58uSzXj/qvgSXmZlpvQIAIA7O9/d5wgJUX1+vK664QuPHj1dpaanee++9rzTHl90AIDWc7+/zhATo1VdfVU1NjdauXav3339fc+bMUUVFhQ4fPpyIuwMAJCOXAPPnz3fBYDDy8eDgoCssLHR1dXXnnQ2FQk4SBwcHB0eSH6FQ6Jx/38f9GdDJkye1d+9elZeXRy5LT09XeXm5Wlpazrj9wMCAwuFw1AEASH1xD9Ann3yiwcFB5efnR12en5+vnp6eM25fV1cnv98fOXgFHABcHMxfBVdbW6tQKBQ5Dh48aL0SAGAExP3ngHJzczVmzBj19vZGXd7b26tAIHDG7X0+n3w+X7zXAACMcnF/BpSRkaG5c+eqsbExctnQ0JAaGxtVVlYW77sDACSphLwTQk1Njaqrq/WNb3xD8+fP1zPPPKP+/n798Ic/TMTdAQCSUEICdPvtt+s///mPHnvsMfX09OjrX/+6tm/ffsYLEwAAF68055yzXuKLwuGw/H6/9RoAgAsUCoWUlZV11uvNXwUHALg4ESAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE3EP0OOPP660tLSoY8aMGfG+GwBAkhubiE967bXX6q233vr/OxmbkLsBACSxhJRh7NixCgQCifjUAIAUkZDvAR04cECFhYWaOnWq7r77bnV1dZ31tgMDAwqHw1EHACD1xT1ApaWlamho0Pbt27VhwwZ1dnbqxhtvVF9f37C3r6urk9/vjxxFRUXxXgkAMAqlOedcIu/g6NGjKi4u1lNPPaV77rnnjOsHBgY0MDAQ+TgcDhMhAEgBoVBIWVlZZ70+4a8OyM7O1tVXX6329vZhr/f5fPL5fIleAwAwyiT854COHTumjo4OFRQUJPquAABJJO4BevDBB9Xc3Kx///vf+vvf/65bb71VY8aM0Z133hnvuwIAJLG4fwnu448/1p133qkjR45o0qRJuuGGG7Rr1y5NmjQp3ncFAEhiCX8RglfhcFh+v996DWDUKS4u9jyzevXqmO5r3rx5nmeCwaDnmf3793ueQfI434sQeC84AIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMBEwn8hHZDqrr76as8zq1at8jzzgx/8wPPMud4IMt7+8pe/eJ5ZsmSJ55lYfmPyRx995HlGklpbW2Oaw1fDMyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYSHPOOeslvigcDsvv91uvgSSXnh7bv62uueYazzM7duzwPBMIBDzPpKK+vj7PM5mZmZ5nWlpaPM9I0o033uh5ZmhoKKb7SkWhUOic78jOMyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwMRY6wWA85k0aZLnmdWrV8d0X4888khMcyMhFAp5nonljTul2N/M1atY9/NqxowZMc3Fch54M9KvjmdAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJ3owUo96vf/1rzzM/+tGPErDJ8E6dOuV55v777/c809nZ6Xlm7dq1nmck6frrr49pbiR88sknnme+//3vx3Rfn332WUxz+Gp4BgQAMEGAAAAmPAdo586dWrJkiQoLC5WWlqatW7dGXe+c02OPPaaCggJNmDBB5eXlOnDgQLz2BQCkCM8B6u/v15w5c1RfXz/s9evXr9ezzz6r5557Trt379all16qiooKnThx4oKXBQCkDs8vQqiqqlJVVdWw1znn9Mwzz+iRRx7RLbfcIkl68cUXlZ+fr61bt+qOO+64sG0BACkjrt8D6uzsVE9Pj8rLyyOX+f1+lZaWqqWlZdiZgYEBhcPhqAMAkPriGqCenh5JUn5+ftTl+fn5keu+rK6uTn6/P3IUFRXFcyUAwChl/iq42tpahUKhyHHw4EHrlQAAIyCuAQoEApKk3t7eqMt7e3sj132Zz+dTVlZW1AEASH1xDVBJSYkCgYAaGxsjl4XDYe3evVtlZWXxvCsAQJLz/Cq4Y8eOqb29PfJxZ2en9u3bp5ycHE2ZMkVr1qzRr371K1111VUqKSnRo48+qsLCQi1dujSeewMAkpznAO3Zs0ff+ta3Ih/X1NRIkqqrq9XQ0KCHHnpI/f39WrlypY4ePaobbrhB27dv1/jx4+O3NQAg6aU555z1El8UDofl9/ut18BXkJ7u/Su4mzdv9jzz+c+UjYTW1lbPMytWrPA8853vfMfzTHV1teeZ6dOne54Z7f761796nqmsrEzAJjifUCh0zu/rm78KDgBwcSJAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJz7+OAfjcT3/6U88zt956awI2OVNbW1tMc08++aTnmXfffdfzjM/n8zyTig4cOOB55sc//nECNoEFngEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACbSnHPOeokvCofD8vv91mtcVMaNGxfTXFdXl+eZ/Pz8mO4r1fz3v//1PPP73//e88yiRYs8z0jSggULYprzqra21vNMLG8YCxuhUEhZWVlnvZ5nQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACAibHWC8De0NBQTHP/+te/PM+M1JuRfvrppzHNDQwMeJ6pr6/3PPPUU095nikqKvI88/DDD3ueidXu3bs9z2zYsCEBmyBZ8AwIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADDBm5FCg4ODMc1997vf9Tzzve99z/PMZ5995nlm3759nmck6cMPP4xpzquJEyd6nlm7dq3nGZ/P53lGko4dO+Z5prq62vNMOBz2PIPUwTMgAIAJAgQAMOE5QDt37tSSJUtUWFiotLQ0bd26Ner65cuXKy0tLeqorKyM174AgBThOUD9/f2aM2fOOX8JV2Vlpbq7uyPHyy+/fEFLAgBSj+cXIVRVVamqquqct/H5fAoEAjEvBQBIfQn5HlBTU5Py8vI0ffp03XfffTpy5MhZbzswMKBwOBx1AABSX9wDVFlZqRdffFGNjY168skn1dzcrKqqqrO+1Leurk5+vz9yxPJ77wEAySfuPwd0xx13RP48a9YszZ49W9OmTVNTU5MWLVp0xu1ra2tVU1MT+TgcDhMhALgIJPxl2FOnTlVubq7a29uHvd7n8ykrKyvqAACkvoQH6OOPP9aRI0dUUFCQ6LsCACQRz1+CO3bsWNSzmc7OTu3bt085OTnKycnRunXrtGzZMgUCAXV0dOihhx7SlVdeqYqKirguDgBIbp4DtGfPHn3rW9+KfPz592+qq6u1YcMGtba26oUXXtDRo0dVWFioxYsX65e//GXM70kFAEhNac45Z73EF4XDYfn9fus1gISK5Y07N27cmIBNhvf88897nlmxYkUCNkEyC4VC5/y+Pu8FBwAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABO8GzZwgXJycjzPNDU1eZ6ZOXOm55mDBw96npGkq666yvPMyZMnY7ovpC7eDRsAMCoRIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACbGWi8AJLvXX3/d80wsbywaiyeeeCKmOd5YFCOBZ0AAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAnejBT4gqlTp3qemTVrVgI2OdObb77peaahoSH+iwBxwjMgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEb0aKlHT55ZfHNNfY2Oh5ZuLEiZ5nDh486HkmGAx6nhkcHPQ8A4wUngEBAEwQIACACU8Bqqur07x585SZmam8vDwtXbpUbW1tUbc5ceKEgsGgLrvsMk2cOFHLli1Tb29vXJcGACQ/TwFqbm5WMBjUrl27tGPHDp06dUqLFy9Wf39/5DYPPPCAXn/9dW3evFnNzc06dOiQbrvttrgvDgBIbp5ehLB9+/aojxsaGpSXl6e9e/dq4cKFCoVCev7557Vp0yZ9+9vfliRt3LhR11xzjXbt2qXrr78+fpsDAJLaBX0PKBQKSZJycnIkSXv37tWpU6dUXl4euc2MGTM0ZcoUtbS0DPs5BgYGFA6How4AQOqLOUBDQ0Nas2aNFixYoJkzZ0qSenp6lJGRoezs7Kjb5ufnq6enZ9jPU1dXJ7/fHzmKiopiXQkAkERiDlAwGNT+/fv1yiuvXNACtbW1CoVCkSOWn48AACSfmH4QddWqVXrjjTe0c+dOTZ48OXJ5IBDQyZMndfTo0ahnQb29vQoEAsN+Lp/PJ5/PF8saAIAk5ukZkHNOq1at0pYtW/T222+rpKQk6vq5c+dq3LhxUT9N3tbWpq6uLpWVlcVnYwBASvD0DCgYDGrTpk3atm2bMjMzI9/X8fv9mjBhgvx+v+655x7V1NQoJydHWVlZWr16tcrKyngFHAAgiqcAbdiwQZJ00003RV2+ceNGLV++XJL09NNPKz09XcuWLdPAwIAqKir0hz/8IS7LAgBSh6cAOefOe5vx48ervr5e9fX1MS8FXKjrrrsuprni4mLPM2lpaZ5n/vSnP3me6erq8jwDjGa8FxwAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMxPQbUYGRNH/+fM8zL7zwQgI2Gd7AwIDnmTfffDMBmwDJhWdAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJ3owUI+rSSy/1PLNu3TrPM9nZ2Z5nYvW///3P88yxY8cSsAmQXHgGBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCY4M1IMaJWrlzpeaaioiIBmwyvp6fH88zNN9/seebDDz/0PAOkGp4BAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmeDNSjKjBwUHPM6FQyPPM008/7XlGkv74xz96nunu7o7pvoCLHc+AAAAmCBAAwISnANXV1WnevHnKzMxUXl6eli5dqra2tqjb3HTTTUpLS4s67r333rguDQBIfp4C1NzcrGAwqF27dmnHjh06deqUFi9erP7+/qjbrVixQt3d3ZFj/fr1cV0aAJD8PL0IYfv27VEfNzQ0KC8vT3v37tXChQsjl19yySUKBALx2RAAkJIu6HtAn786KScnJ+ryl156Sbm5uZo5c6Zqa2t1/Pjxs36OgYEBhcPhqAMAkPpifhn20NCQ1qxZowULFmjmzJmRy++66y4VFxersLBQra2tevjhh9XW1qbXXntt2M9TV1endevWxboGACBJxRygYDCo/fv369133426fOXKlZE/z5o1SwUFBVq0aJE6Ojo0bdq0Mz5PbW2tampqIh+Hw2EVFRXFuhYAIEnEFKBVq1bpjTfe0M6dOzV58uRz3ra0tFSS1N7ePmyAfD6ffD5fLGsAAJKYpwA557R69Wpt2bJFTU1NKikpOe/Mvn37JEkFBQUxLQgASE2eAhQMBrVp0yZt27ZNmZmZ6unpkST5/X5NmDBBHR0d2rRpk26++WZddtllam1t1QMPPKCFCxdq9uzZCfkPAAAkJ08B2rBhg6TTP2z6RRs3btTy5cuVkZGht956S88884z6+/tVVFSkZcuW6ZFHHonbwgCA1OD5S3DnUlRUpObm5gtaCABwcUhz56vKCAuHw/L7/dZrAAAuUCgUUlZW1lmv581IAQAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMDHqAuScs14BABAH5/v7fNQFqK+vz3oFAEAcnO/v8zQ3yp5yDA0N6dChQ8rMzFRaWlrUdeFwWEVFRTp48KCysrKMNrTHeTiN83Aa5+E0zsNpo+E8OOfU19enwsJCpaef/XnO2BHc6StJT0/X5MmTz3mbrKysi/oB9jnOw2mch9M4D6dxHk6zPg9+v/+8txl1X4IDAFwcCBAAwERSBcjn82nt2rXy+XzWq5jiPJzGeTiN83Aa5+G0ZDoPo+5FCACAi0NSPQMCAKQOAgQAMEGAAAAmCBAAwETSBKi+vl5XXHGFxo8fr9LSUr333nvWK424xx9/XGlpaVHHjBkzrNdKuJ07d2rJkiUqLCxUWlqatm7dGnW9c06PPfaYCgoKNGHCBJWXl+vAgQM2yybQ+c7D8uXLz3h8VFZW2iybIHV1dZo3b54yMzOVl5enpUuXqq2tLeo2J06cUDAY1GWXXaaJEydq2bJl6u3tNdo4Mb7KebjpppvOeDzce++9RhsPLykC9Oqrr6qmpkZr167V+++/rzlz5qiiokKHDx+2Xm3EXXvtteru7o4c7777rvVKCdff3685c+aovr5+2OvXr1+vZ599Vs8995x2796tSy+9VBUVFTpx4sQIb5pY5zsPklRZWRn1+Hj55ZdHcMPEa25uVjAY1K5du7Rjxw6dOnVKixcvVn9/f+Q2DzzwgF5//XVt3rxZzc3NOnTokG677TbDrePvq5wHSVqxYkXU42H9+vVGG5+FSwLz5893wWAw8vHg4KArLCx0dXV1hluNvLVr17o5c+ZYr2FKktuyZUvk46GhIRcIBNxvf/vbyGVHjx51Pp/PvfzyywYbjowvnwfnnKuurna33HKLyT5WDh8+7CS55uZm59zp//fjxo1zmzdvjtzmn//8p5PkWlparNZMuC+fB+ec++Y3v+nuv/9+u6W+glH/DOjkyZPau3evysvLI5elp6ervLxcLS0thpvZOHDggAoLCzV16lTdfffd6urqsl7JVGdnp3p6eqIeH36/X6WlpRfl46OpqUl5eXmaPn267rvvPh05csR6pYQKhUKSpJycHEnS3r17derUqajHw4wZMzRlypSUfjx8+Tx87qWXXlJubq5mzpyp2tpaHT9+3GK9sxp1b0b6ZZ988okGBweVn58fdXl+fr4+/PBDo61slJaWqqGhQdOnT1d3d7fWrVunG2+8Ufv371dmZqb1eiZ6enokadjHx+fXXSwqKyt12223qaSkRB0dHfrFL36hqqoqtbS0aMyYMdbrxd3Q0JDWrFmjBQsWaObMmZJOPx4yMjKUnZ0dddtUfjwMdx4k6a677lJxcbEKCwvV2tqqhx9+WG1tbXrttdcMt4026gOE/1dVVRX58+zZs1VaWqri4mL9+c9/1j333GO4GUaDO+64I/LnWbNmafbs2Zo2bZqampq0aNEiw80SIxgMav/+/RfF90HP5WznYeXKlZE/z5o1SwUFBVq0aJE6Ojo0bdq0kV5zWKP+S3C5ubkaM2bMGa9i6e3tVSAQMNpqdMjOztbVV1+t9vZ261XMfP4Y4PFxpqlTpyo3NzclHx+rVq3SG2+8oXfeeSfq17cEAgGdPHlSR48ejbp9qj4eznYehlNaWipJo+rxMOoDlJGRoblz56qxsTFy2dDQkBobG1VWVma4mb1jx46po6NDBQUF1quYKSkpUSAQiHp8hMNh7d69+6J/fHz88cc6cuRISj0+nHNatWqVtmzZorffflslJSVR18+dO1fjxo2Lejy0tbWpq6srpR4P5zsPw9m3b58kja7Hg/WrIL6KV155xfl8PtfQ0OD+8Y9/uJUrV7rs7GzX09NjvdqI+tnPfuaamppcZ2en+9vf/ubKy8tdbm6uO3z4sPVqCdXX1+c++OAD98EHHzhJ7qmnnnIffPCB++ijj5xzzv3mN79x2dnZbtu2ba61tdXdcsstrqSkxH366afGm8fXuc5DX1+fe/DBB11LS4vr7Ox0b731lrvuuuvcVVdd5U6cOGG9etzcd999zu/3u6amJtfd3R05jh8/HrnNvffe66ZMmeLefvttt2fPHldWVubKysoMt46/852H9vZ298QTT7g9e/a4zs5Ot23bNjd16lS3cOFC482jJUWAnHPud7/7nZsyZYrLyMhw8+fPd7t27bJeacTdfvvtrqCgwGVkZLjLL7/c3X777a69vd16rYR75513nKQzjurqaufc6ZdiP/rooy4/P9/5fD63aNEi19bWZrt0ApzrPBw/ftwtXrzYTZo0yY0bN84VFxe7FStWpNw/0ob775fkNm7cGLnNp59+6n7yk5+4r33ta+6SSy5xt956q+vu7rZbOgHOdx66urrcwoULXU5OjvP5fO7KK690P//5z10oFLJd/Ev4dQwAABOj/ntAAIDURIAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCY+D8JMsCiw83XfwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels:  9\n",
            "predicted:  9\n",
            "(0.3517108608782291, 10000, 90.08)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#20\n",
        "torch.save(model.state_dict(), \"MNIST.pth\")\n",
        "model.state_dict()"
      ],
      "metadata": {
        "id": "p9Tq1Ttsfbyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model=MNISTMODEL(input_size, hidden_size1, hidden_size2, output_size)\n",
        "saved_model.load_state_dict(torch.load('MNIST.pth'))\n",
        "saved_model.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgEx63M7ouwh",
        "outputId": "1b21cc7e-dcc9-4b15-f01c-57ac8907537d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-450330895b00>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  saved_model.load_state_dict(torch.load('MNIST.pth'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('linear1.weight',\n",
              "              tensor([[ 0.0309, -0.0147, -0.0004,  ..., -0.0085,  0.0245, -0.0021],\n",
              "                      [-0.0130, -0.0012,  0.0206,  ..., -0.0162, -0.0222,  0.0155],\n",
              "                      [ 0.0034, -0.0287, -0.0199,  ...,  0.0281,  0.0024, -0.0180],\n",
              "                      ...,\n",
              "                      [-0.0086, -0.0159, -0.0022,  ..., -0.0001,  0.0351, -0.0111],\n",
              "                      [-0.0244, -0.0195,  0.0345,  ..., -0.0222, -0.0320,  0.0198],\n",
              "                      [-0.0317, -0.0181,  0.0255,  ..., -0.0042, -0.0212,  0.0119]])),\n",
              "             ('linear1.bias',\n",
              "              tensor([ 3.1300e-02,  4.4668e-02,  1.5617e-02,  1.8764e-02,  7.5081e-02,\n",
              "                       3.0093e-02, -1.8613e-02, -1.1791e-02, -4.8617e-03,  6.2139e-02,\n",
              "                      -1.3675e-03,  5.0789e-02, -4.3445e-02, -4.8329e-04,  4.3572e-03,\n",
              "                       2.2874e-02, -4.8038e-05, -8.8091e-03,  9.5547e-04,  1.8695e-02,\n",
              "                       3.4536e-02,  3.1684e-02, -1.5120e-03,  2.5258e-02, -1.3219e-02,\n",
              "                       1.5424e-02,  3.8381e-02, -1.5327e-02,  2.8312e-02,  3.5237e-03,\n",
              "                       3.3000e-02,  3.1404e-02, -3.8400e-02,  2.7971e-04,  2.6963e-02,\n",
              "                       2.3869e-03,  3.5472e-02,  2.5999e-03,  5.4101e-02,  4.3444e-02,\n",
              "                       3.4469e-02,  2.6826e-02,  3.1174e-02,  1.2653e-02, -1.8914e-02,\n",
              "                      -2.4741e-02,  1.7945e-02,  1.2408e-02,  2.5572e-03, -2.7390e-02,\n",
              "                       3.3883e-03, -1.2373e-02, -3.1246e-03, -1.7508e-02,  2.9219e-03,\n",
              "                       6.7000e-02, -1.7690e-02, -2.9594e-02, -1.3431e-02, -2.9810e-02,\n",
              "                       5.8251e-02,  1.4077e-02,  1.8054e-02,  1.7867e-02,  3.1247e-03,\n",
              "                      -1.1899e-02,  1.6176e-02,  1.8433e-02,  2.1607e-02,  1.3164e-02,\n",
              "                       4.9528e-02, -2.8842e-03,  3.2954e-02,  4.0818e-02,  1.0200e-02,\n",
              "                      -3.2594e-03,  1.1853e-02,  2.9393e-02,  5.4860e-03,  2.2657e-02,\n",
              "                      -4.6796e-03,  3.6237e-02, -2.1372e-02,  4.8607e-02,  2.3330e-02,\n",
              "                      -9.0065e-03,  6.6906e-02, -1.8633e-03,  6.2638e-02,  2.6532e-02,\n",
              "                       1.7915e-03,  1.2640e-02,  2.7376e-02,  1.7805e-03, -5.9608e-03,\n",
              "                       7.5799e-03, -1.3630e-02, -2.4104e-02, -1.1154e-02,  8.9888e-03,\n",
              "                      -1.1695e-02,  3.2910e-03, -9.8046e-04, -2.3687e-03, -8.4281e-03,\n",
              "                       2.6657e-02,  3.1641e-02,  2.2554e-02,  5.8454e-02,  1.0853e-02,\n",
              "                      -1.6064e-03,  2.3368e-02,  2.1805e-02,  7.9496e-03,  5.7527e-02,\n",
              "                       5.8119e-02,  9.4656e-03,  1.8030e-02,  1.2977e-02, -2.2349e-02,\n",
              "                      -6.9033e-03,  3.0121e-02,  2.5056e-02,  5.3673e-02, -1.3923e-02,\n",
              "                       1.5385e-02,  2.8895e-03,  3.1350e-02,  1.6887e-02, -9.3610e-03,\n",
              "                      -1.1166e-02,  3.6582e-02, -9.0971e-03, -1.6133e-02, -4.3950e-03,\n",
              "                       3.1403e-02,  8.8958e-02,  4.0766e-02,  9.0449e-04, -5.2000e-03,\n",
              "                       3.3253e-02,  4.4971e-02,  1.2372e-02, -2.5110e-02, -9.3445e-03,\n",
              "                       5.5238e-03, -2.3112e-03,  3.0232e-02, -3.6991e-03, -5.7369e-02,\n",
              "                       9.7862e-03,  1.2303e-02,  1.2834e-02,  4.6157e-02, -4.7057e-03,\n",
              "                       2.4245e-02, -4.0562e-03,  3.8199e-02,  1.7623e-02, -6.5337e-03,\n",
              "                      -8.9164e-03,  3.1517e-03, -1.0335e-02, -4.0038e-03,  1.4224e-02,\n",
              "                      -1.2738e-02,  4.5772e-03,  1.2882e-02,  1.7224e-02, -1.3284e-02,\n",
              "                      -2.6071e-02,  2.7573e-02,  3.8827e-02, -2.2734e-02,  5.4975e-02,\n",
              "                       1.6186e-02,  2.9165e-02,  4.4567e-02,  2.2472e-02, -1.6668e-02,\n",
              "                      -2.2445e-02,  3.0197e-03,  2.8660e-03,  2.8444e-02, -1.1127e-02,\n",
              "                       2.2759e-02,  2.0446e-02, -3.0901e-02,  4.1147e-02,  1.8969e-02,\n",
              "                       3.5989e-02,  3.3546e-02,  4.3881e-02, -1.2908e-02,  2.4537e-02,\n",
              "                      -2.0864e-02, -2.7773e-02,  1.7871e-02,  7.9657e-03,  2.5141e-03,\n",
              "                      -1.1684e-02, -1.7226e-02, -7.5098e-03,  4.0772e-03,  1.1397e-02,\n",
              "                      -2.6828e-02, -2.6750e-02,  4.8564e-03, -5.2550e-03,  2.3433e-02,\n",
              "                      -5.0912e-04, -5.8128e-03,  1.0589e-02,  3.4642e-03,  3.0865e-03,\n",
              "                       1.0881e-02,  2.5855e-03, -9.6244e-03,  1.8612e-02, -6.3014e-03,\n",
              "                       7.2749e-02,  3.4298e-02,  1.2446e-02,  5.1609e-02,  3.5244e-02,\n",
              "                      -1.4832e-03, -1.4833e-02,  3.9902e-02, -3.3306e-03, -2.3232e-02,\n",
              "                       3.2726e-02,  1.5478e-02,  3.8977e-02, -1.3996e-02,  3.2112e-02,\n",
              "                       4.6060e-02, -2.7657e-02,  2.0260e-03,  4.0493e-02, -1.8305e-02,\n",
              "                       4.7943e-02, -2.4611e-02,  4.3990e-02, -1.9809e-02,  2.7781e-02,\n",
              "                      -3.1152e-02, -8.9023e-03,  3.4385e-02, -7.9958e-04, -5.4336e-03,\n",
              "                       5.6279e-03,  4.2387e-02,  1.2974e-02,  8.4533e-03,  4.0302e-02,\n",
              "                      -1.7264e-02])),\n",
              "             ('linear2.weight',\n",
              "              tensor([[-0.0186, -0.0099,  0.0490,  ..., -0.0438,  0.0123, -0.0448],\n",
              "                      [-0.0043,  0.0246,  0.0066,  ...,  0.0266, -0.0406, -0.0535],\n",
              "                      [ 0.0606,  0.0427,  0.0554,  ..., -0.0104, -0.0073,  0.0510],\n",
              "                      ...,\n",
              "                      [ 0.0561,  0.1121, -0.0279,  ..., -0.0345, -0.0464, -0.0217],\n",
              "                      [-0.0029,  0.0203,  0.0415,  ...,  0.0784, -0.0160,  0.0027],\n",
              "                      [ 0.0509, -0.0426, -0.0087,  ...,  0.0157,  0.0180,  0.0369]])),\n",
              "             ('linear2.bias',\n",
              "              tensor([-0.0035,  0.0083, -0.0166, -0.0502, -0.0510,  0.0565, -0.0075,  0.0357,\n",
              "                       0.0227,  0.0498, -0.0324, -0.0316, -0.0422,  0.0147, -0.0047, -0.0166,\n",
              "                      -0.0316,  0.0776, -0.0534,  0.0251,  0.0454, -0.0063, -0.0546, -0.0681,\n",
              "                       0.0847,  0.0204,  0.0330,  0.0519,  0.0481, -0.0634,  0.0365, -0.0385,\n",
              "                      -0.0605, -0.0032,  0.0330,  0.0501, -0.0303, -0.0156,  0.0093,  0.0131,\n",
              "                      -0.0858,  0.0261,  0.0513,  0.0905,  0.0076,  0.0441,  0.0063,  0.0328,\n",
              "                      -0.0335,  0.0192,  0.0032,  0.0577,  0.0881,  0.0351, -0.0431,  0.0105,\n",
              "                       0.0263,  0.0753,  0.0631,  0.0614,  0.0768,  0.0364,  0.0651,  0.0069,\n",
              "                      -0.0247,  0.0035,  0.0113, -0.0058, -0.0380, -0.0353, -0.0597, -0.0412,\n",
              "                      -0.0388,  0.0793,  0.0358,  0.0523,  0.0254, -0.0391, -0.0163,  0.0803,\n",
              "                       0.0277,  0.0331, -0.0104,  0.0342,  0.1109, -0.0046, -0.0359,  0.0353,\n",
              "                      -0.0369,  0.0861,  0.0907, -0.0493, -0.0237,  0.0363, -0.0193,  0.1013,\n",
              "                       0.0378,  0.0170,  0.0049,  0.0406, -0.0305, -0.0227,  0.0850,  0.0116,\n",
              "                       0.0711,  0.0862,  0.0694, -0.0314,  0.0431,  0.0159, -0.0146,  0.0022,\n",
              "                       0.0464,  0.0451,  0.0349,  0.0890,  0.0021,  0.0150, -0.0145,  0.0490,\n",
              "                      -0.0484,  0.0679, -0.0345,  0.0442,  0.0972,  0.0649,  0.0765, -0.0307])),\n",
              "             ('linear3.weight',\n",
              "              tensor([[-0.0707, -0.0133,  0.0185,  ..., -0.2258, -0.1576, -0.0962],\n",
              "                      [-0.1328, -0.0961,  0.0518,  ..., -0.2019, -0.0448,  0.1603],\n",
              "                      [ 0.1161, -0.1627, -0.0339,  ...,  0.0598,  0.0801, -0.0587],\n",
              "                      ...,\n",
              "                      [-0.1766,  0.0844, -0.0004,  ...,  0.2951, -0.0714,  0.0580],\n",
              "                      [ 0.1224,  0.0200,  0.0678,  ...,  0.1297, -0.0595, -0.0491],\n",
              "                      [-0.0462,  0.0708,  0.0522,  ...,  0.2798,  0.1227, -0.1291]])),\n",
              "             ('linear3.bias',\n",
              "              tensor([-0.1349,  0.1772, -0.0380,  0.0647,  0.0166,  0.1594,  0.0326,  0.0499,\n",
              "                      -0.1550, -0.0564]))])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CXI70r7OpI8w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}